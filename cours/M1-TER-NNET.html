---
title: "NNet / Traitement automatique des langues"
date: 2018-01-08
layout: post
categories: 
tags: 
- cours 
- M1 
- TER 
- NNet
published: true
comments: 
---
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org74db75e">News et TODO-list</a>
<ul>
<li><a href="#orgf2efb15">à faire et à rendre pour le 07 mars</a></li>
<li><a href="#org74ddb7f">à faire pour le 14/02</a></li>
<li><a href="#org94054cb">à faire pour le 24/01</a></li>
<li><a href="#org534c705">Première séance le 10/01, et la seconde aura lieu le 24/01</a></li>
</ul>
</li>
<li><a href="#orgec1422e">Contenu</a>
<ul>
<li><a href="#org0668034">Séance 1 : le 10/01</a></li>
<li><a href="#org7be7019">Séance 2 : le 24/01</a>
<ul>
<li><a href="#org3599d6d">Eléments de correction</a></li>
</ul>
</li>
<li><a href="#org2265ac6">Séance 3 : le 31/01</a></li>
<li><a href="#orgcba0153">Séance 4 : le 07/02</a></li>
<li><a href="#org7bf46b0">Séance 5 : le 07/03</a></li>
</ul>
</li>
<li><a href="#org3336442">Projets</a>
<ul>
<li><a href="#org72c8eeb">Notation automatique de réponses courtes à des questions</a></li>
<li><a href="#org4171c82">Notation (et explication) pour les bières</a></li>
<li><a href="#org9e45f26">Airline Travel Information System (ATIS)</a></li>
<li><a href="#orga0fdfa2">Classification de tweets</a></li>
<li><a href="#orgc2e8b09">Conversion graphèmes vers phonèmes</a></li>
<li><a href="#orgaed6fb3">Q&amp;A insurance</a></li>
<li><a href="#org89455f1">bAbI task de facebook</a></li>
</ul>
</li>
<li><a href="#org8ad32cf">Contexte</a></li>
</ul>
</div>
</div>
<hr>

<p>
Le <b><b>dossier partagé</b></b> pour ce cours est le <a href="https://ocsync.limsi.fr/index.php/s/qeHOwyR9jVheFjC">suivant</a>. Vous y trouverez
les cours et les ressources nécessaires. 
</p>

<div id="outline-container-org74db75e" class="outline-2">
<h2 id="org74db75e">News et TODO-list</h2>
<div class="outline-text-2" id="text-org74db75e">
</div>
<div id="outline-container-orgf2efb15" class="outline-3">
<h3 id="orgf2efb15">à faire et à rendre pour le 07 mars</h3>
<div class="outline-text-3" id="text-orgf2efb15">
<p>
Le travail à rendre est un bilan de ce que vous avez fait sur les derniers TPs sur la classification de textes sur les données imdb. Ce qui est attendu:
</p>
<ul class="org-ul">
<li>classifieur simple, la régression logistique</li>
<li>un réseau de neurone réalisant une régression logistique, mais un texte est vu comme un sac de mots et chaque mot est représenté par son embedding. Le modèle est donc une régression logistique branchée sur un <i>sac de word embeddings</i>.</li>
</ul>
<p>
Pour ces deux classifieurs, la démarche expérimentale est la même : 
</p>
<ul class="org-ul">
<li>à partir d'une partition des données en train/dev/test</li>
</ul>
<p>
Format : un notebook avec les résultats 
</p>
</div>
</div>

<div id="outline-container-org74ddb7f" class="outline-3">
<h3 id="org74ddb7f">à faire pour le 14/02</h3>
<div class="outline-text-3" id="text-org74ddb7f">
<p>
Partant de la correction sur la regression logistique. Effectuer
l'apprentissage sur les données imdb, soit le TP3.  Le travail était à
faire pour le 07/02, mais suite aux intempéries, la séance a été
reportée.
</p>
</div>
</div>



<div id="outline-container-org94054cb" class="outline-3">
<h3 id="org94054cb">à faire pour le 24/01</h3>
<div class="outline-text-3" id="text-org94054cb">
<ul class="org-ul">
<li>Il faut  finir le TP1. La partie importante est la dernière sur
l'exploration de données. Un objectif est d'obtenir une liste de
mots pour représenter les textes. Cette liste est obtenue à partir
des mots observés dans les textes positifs <b><b>et</b></b> négatifs. On peut
supprimer par exemple les mots les plus fréquents qui apparaissent
dans les 2 catégories.</li>

<li>Relire le cours, du moins les 2 premières parties et faire la liste
des questions, s'il y en a.</li>
</ul>
</div>
</div>

<div id="outline-container-org534c705" class="outline-3">
<h3 id="org534c705">Première séance le 10/01, et la seconde aura lieu le 24/01</h3>
</div>
</div>

<div id="outline-container-orgec1422e" class="outline-2">
<h2 id="orgec1422e">Contenu</h2>
<div class="outline-text-2" id="text-orgec1422e">
</div>
<div id="outline-container-org0668034" class="outline-3">
<h3 id="org0668034">Séance 1 : le 10/01</h3>
<div class="outline-text-3" id="text-org0668034">
<ul class="org-ul">
<li>Cours: Classification binaire / Séparation linéaire</li>
<li>TP : Prise en main python et données imdb</li>
</ul>
</div>
</div>



<div id="outline-container-org7be7019" class="outline-3">
<h3 id="org7be7019">Séance 2 : le 24/01</h3>
<div class="outline-text-3" id="text-org7be7019">
<ul class="org-ul">
<li>Cours: Régression logistique, fontcion de coût et optimisation</li>
<li>TP : Prise en main de pytorch</li>
</ul>
</div>

<div id="outline-container-org3599d6d" class="outline-4">
<h4 id="org3599d6d">Eléments de correction</h4>
<div class="outline-text-4" id="text-org3599d6d">
<p>
Pour dessiner les données (tous les points en noir)
</p>
<div class="org-src-container">
<pre class="src src-python">plt.title(<span style="color: #ffa07a;">'Toy example: the raw data'</span>)
plotData(ST1,ST2,-<span style="color: #ffffff; background-color: #000000;">1</span>. ,<span style="color: #ffffff; background-color: #000000;">21</span>, <span style="color: #ffffff; background-color: #000000;">opt1</span>=<span style="color: #ffa07a;">'ko'</span>, <span style="color: #ffffff; background-color: #000000;">opt2</span>=<span style="color: #ffa07a;">'ko'</span> )
plt.show()
</pre>
</div>
<p>
Pour dessiner les données (chacun sa couleur)
</p>

<div class="org-src-container">
<pre class="src src-python">plt.title(<span style="color: #ffa07a;">'Toy example: the data with classes'</span>)
plotData(ST1,ST2,-<span style="color: #ffffff; background-color: #000000;">1</span>. ,<span style="color: #ffffff; background-color: #000000;">21</span>)
plt.show()
</pre>
</div>
<p>
En ajoutant une droite séparatrice
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">x + y = 20 -&gt; -20 + x + y = 0 </span>
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">bias = -20 ; vecteur normal: (1,1)</span>
plt.title(<span style="color: #ffa07a;">'Toy example: a first solution'</span>)
plotDroite( matrix(<span style="color: #ffa07a;">'-20 ; 1 ; 1'</span>), -<span style="color: #ffffff; background-color: #000000;">1</span>, <span style="color: #ffffff; background-color: #000000;">21</span>)
plotData(ST1,ST2,-<span style="color: #ffffff; background-color: #000000;">1</span>. ,<span style="color: #ffffff; background-color: #000000;">21</span>)
plt.show()
</pre>
</div>


<p>
Pour la dernière partie, le plan est: 
</p>
<ul class="org-ul">
<li>définir le modèle</li>
<li>la fonction objectif (de coût) à optimiser (minimiser ici)</li>
<li>le choix d'un optimiseur qui permet d'adapter le pas de gradient</li>
</ul>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #00ffff;">import</span> torch <span style="color: #00ffff;">as</span> th
<span style="color: #00ffff;">import</span> torch.autograd <span style="color: #00ffff;">as</span> ag
<span style="color: #00ffff;">import</span> torch.nn.functional <span style="color: #00ffff;">as</span> F
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">set the seed (reproductibility)</span>
torch.manual_seed(<span style="color: #ffffff; background-color: #000000;">1</span>) 
<span style="color: #ffffff; background-color: #000000;">D_in</span> = <span style="color: #ffffff; background-color: #000000;">2</span>
<span style="color: #ffffff; background-color: #000000;">D_out</span>= <span style="color: #ffffff; background-color: #000000;">1</span>
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Use the nn package to define our model and loss function</span>
<span style="color: #ffffff; background-color: #000000;">model</span> = th.nn.Sequential(
    th.nn.Linear(D_in, D_out),
    th.nn.Sigmoid()    
)
<span style="color: #ffffff; background-color: #000000;">loss_fn</span> = th.nn.BCELoss()
<span style="color: #ffffff; background-color: #000000;">learning_rate</span> = 1e-<span style="color: #ffffff; background-color: #000000;">1</span>
<span style="color: #ffffff; background-color: #000000;">optimizer</span> = torch.optim.SGD(model.parameters(), <span style="color: #ffffff; background-color: #000000;">lr</span>=learning_rate)
</pre>
</div>

<p>
Reste à écrire la boucle d'apprentissage pour la semaine prochaine. 
</p>
</div>
</div>
</div>
<div id="outline-container-org2265ac6" class="outline-3">
<h3 id="org2265ac6">Séance 3 : le 31/01</h3>
<div class="outline-text-3" id="text-org2265ac6">
<ul class="org-ul">
<li>TP : pytorch / regression logistique suite et fin + imdb</li>
</ul>

<p>
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
</p>
</div>
</div>
<div id="outline-container-orgcba0153" class="outline-3">
<h3 id="orgcba0153">Séance 4 : le 07/02</h3>
<div class="outline-text-3" id="text-orgcba0153">
<p>
Voir le travail à faire pour <b><b>avant</b></b> la séance: Finir la regression
logistique sur imdb. 
</p>
</div>
</div>
<div id="outline-container-org7bf46b0" class="outline-3">
<h3 id="org7bf46b0">Séance 5 : le 07/03</h3>
<div class="outline-text-3" id="text-org7bf46b0">
<ul class="org-ul">
<li>cours : Softmax et modèle récurrent</li>
<li>TP : POS-tagging avec des réseaux récurrents</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org3336442" class="outline-2">
<h2 id="org3336442">Projets</h2>
<div class="outline-text-2" id="text-org3336442">
<p>
<b>Pour le mercredi 21/03/2018</b>, vous devez choisir un projet à faire, soit
parmi ceux listés ci-dessous, soit en proposer un, soit on en discute. Puis vous devez
explorer et décrire la tâche en me écrivant un notebook.
</p>

<p>
De manière général, face à un nouveau projet et de nouvelles données, il
faut :
</p>

<ul class="org-ul">
<li>regarder la taille du vocabulaire (en nombre de mots)</li>
<li>est-il possible de le réduire à une taille acceptable ? par exemple
en excluant les mots dont la fréquence est en dessous d'un certain
seuil.</li>
<li>le nombre de caractères</li>
<li>le nombre de phrase (ou de document) à traiter pour l'apprentissage
et pour le test</li>
<li>parfois, c'est à vous de créer la partition (apprentissage,
validation, test)</li>
<li>la distribution de longueurs de phrases.</li>
</ul>

<p>
L'objectif de ce notebook sera d'analyser les données et la tâche afin
de proposer des solutions à expérimenter. Il peut être bien également de
regarder la métrique d'évaluation et voir quels sont les résultats
obtenus par l'état de l'art.
</p>
</div>

<div id="outline-container-org72c8eeb" class="outline-3">
<h3 id="org72c8eeb">Notation automatique de réponses courtes à des questions</h3>
<div class="outline-text-3" id="text-org72c8eeb">
<p>
Les données sont <a href="http://web.eecs.umich.edu/~mihalcea/downloads/ShortAnswerGrading_v2.0.zip">ici pour le téléchargement</a> et leur description est
<a href="http://aclweb.org/anthology/P11-1076">dans cet article</a>. 
</p>

<p>
Lorsque l'on connait:
</p>

<ul class="org-ul">
<li>une question,</li>
<li>une réponse d'un étudiant,</li>
<li>la bonne réponse,</li>
</ul>

<p>
comment prédire la note à donné à la réponse de l'étudiant. Il peut être
aussi intéressant d'essayer d'apprendre à générer la réponse.
</p>
</div>
</div>


<div id="outline-container-org4171c82" class="outline-3">
<h3 id="org4171c82">Notation (et explication) pour les bières</h3>
<div class="outline-text-3" id="text-org4171c82">
<p>
Les données sont disponibles <a href="http://jmcauley.ucsd.edu/cse255/data/beer/beer_50000.json">ici en json</a>. Un exemple d'utilisation de
ces données est décrit dans <a href="https://people.csail.mit.edu/taolei/papers/emnlp16_rationale.pdf">cet article</a>. Mais on peut envisager des
choses plus simple: 
</p>
<ul class="org-ul">
<li>juste un classifieur pour assigner plusieurs notes</li>
<li>expliquer la note pour un classifier plus simple</li>
<li>&#x2026;</li>
</ul>
</div>
</div>

<div id="outline-container-org9e45f26" class="outline-3">
<h3 id="org9e45f26">Airline Travel Information System (ATIS)</h3>
<div class="outline-text-3" id="text-org9e45f26">
<p>
Corpus des années 90, il est dédié à la compréhension de la parole. Le
but est de faire de l'étiquetage de séquence. En entrée, une phrase est
une séquence de mots, et le but est de lui associé une séquence
d'étiquette, une par mot.
</p>

<ul class="org-ul">
<li>Show flights from Boston to New York today</li>
<li>O O O B-dept O B-arr I-arr B-date</li>
</ul>

<p>
Ainsi le mot Show est associé à 'O' pour 'other'; 'Boston' est associé
au lieu de départ, 'B-dept' signifie 'début de départ'; 'York' est
'Inside arrival', &#x2026;
</p>
</div>
</div>

<div id="outline-container-orga0fdfa2" class="outline-3">
<h3 id="orga0fdfa2">Classification de tweets</h3>
<div class="outline-text-3" id="text-orga0fdfa2">
<p>
Partant d'un tweet vu comme une séquence de symboles, effectuer une
classification binaire (positif/négatif). Les données peuvent se
<a href="http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip">télécharger
ici</a>.
</p>

<p>
Un axe peut être de développer un modèle efficace. Les étapes
importantes:
</p>

<ul class="org-ul">
<li>Exploration puis préparation des données sous forme exploitable</li>
<li>Filtrage des données éventuel</li>
<li>Préparation d'une partition : apprentissage, validation, test</li>
<li>essayer différents modèles</li>
</ul>

<p>
Un autre axe est de partir de cet article
<a href="https://www-cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf">en
pdf</a> qui parle, entre autre, de comment collecter des données tweeter
pour faire de la classification.
</p>
</div>
</div>

<div id="outline-container-orgc2e8b09" class="outline-3">
<h3 id="orgc2e8b09">Conversion graphèmes vers phonèmes</h3>
<div class="outline-text-3" id="text-orgc2e8b09">
<p>
Partant d'un mot vue comme une séquence de lettres (les graphèmes), le
but est de générer une séquence de phonèmes. Les données nettalk sont
décrites
<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.names">ici</a>
et disponible
<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.data">ici</a>.
</p>

<p>
Il y a deux types d'annotation que l'on peut vouloir générer :
</p>

<ul class="org-ul">
<li>au moins la séquence de phonèmes (c'est le but premier),</li>
<li>mais également la séquence d'accentuation.</li>
</ul>

<p>
La séquence d'accentuation peut éventuellement aider à prédire les
phonèmes. Il existe alors plusieurs pistes à explorer.
</p>

<p>
Remarque : penser à vérifier si la séquence à générer est toujours de la
même longueur que la séquence de graphèmes
</p>
</div>
</div>

<div id="outline-container-orgaed6fb3" class="outline-3">
<h3 id="orgaed6fb3">Q&amp;A insurance</h3>
<div class="outline-text-3" id="text-orgaed6fb3">
<p>
L'objectif est pouvoir sélectionner une réponse à une question. Les
données viennent du domaine de l'assurance. Les données brutes viennent
<a href="https://github.com/shuzi/insuranceQA.git">de ce site</a>.
</p>

<p>
Une version plus simple peut se télécharger
<a href="https://github.com/codekansas/insurance_qa_python">ici</a>
</p>

<p>
Cette
<a href="http://benjaminbolte.com/blog/2016/keras-language-modeling.html">page</a>
explique beaucoup de choses (certaines sont peut être soit trop
complexes, soit inutiles). Elle cite entre autres des articles décrivant
des modèles performants et qui peuvent donner des idées.
</p>
</div>
</div>




<div id="outline-container-org89455f1" class="outline-3">
<h3 id="org89455f1">bAbI task de facebook</h3>
<div class="outline-text-3" id="text-org89455f1">
<p>
Les données sont décrite sur
<a href="https://research.fb.com/projects/babi/">cette page</a> et surtout dans
<a href="http://arxiv.org/abs/1502.05698">cet article</a>.
</p>

<p>
Un exemple de démarrage est donné dans
<a href="https://github.com/fchollet/keras/blob/master/examples/babi_rnn.py">ce
code</a>. Plusieurs tâches sont intéressantes.
</p>
</div>
</div>
</div>




<div id="outline-container-org8ad32cf" class="outline-2">
<h2 id="org8ad32cf">Contexte</h2>
<div class="outline-text-2" id="text-org8ad32cf">
<p>
Les réseaux de neurones profonds occupent aujourd'hui une place très
importante dans les technologies de la langues et la vision par
ordinateur. Dans les applications récentes, on notera:
</p>

<ul class="org-ul">
<li><a href="http://googleresearch.blogspot.fr/2015/11/computer-respond-to-this-email.html">la réponse automatique aux emails</a>,</li>
<li><a href="http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html">la génération automatique de légendes d'image</a>,</li>
<li>la reconnaissance automatique de la parole pour effectuer des
recherches sur téléphone portable,</li>
<li>la synthèse de la parole,</li>
<li>la traduction automatique.</li>
</ul>

<p>
Le but de ce TER est d'aborder un problème réel et de développer des
modèles neuronaux capables d'apprendre des tâches difficiles du
traitement automatique des langues comme la classification ou la
génération de texte. Ce TER utilisera la bibliothèque
<a href="http://pytorch.org/">pytyorch</a> (en python).
</p>

<p>
Le TER démarre par des cours et TP permettant aux étudiants de comprendre les bases nécessaires concernant les réseaux de neurones artificiels et leur manipulation. Puis différent projets seront proposés, parmi lesquels les étudiants en binôme devront choisir ou en proposer un.
</p>

<p>
Un plan indicatif des cours (en construction):
</p>

<ul class="org-ul">
<li>Régression logistique, le neurone artificiel

<ul class="org-ul">
<li>Classification binaire de texte</li>
<li>Modèle probabiliste</li>
<li>Fonction objectif</li>
<li>Algorithme d'apprentissage</li>
</ul></li>

<li>Représentation de mots

<ul class="org-ul">
<li>Un premier réseau de neurones</li>
<li>Word embeddings</li>
</ul></li>

<li>Représentation des séquences de mots</li>
</ul>
</div>
</div>
