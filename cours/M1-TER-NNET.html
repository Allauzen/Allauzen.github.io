---
title: "NNet / Traitement automatique des langues"
date: 2018-01-08
layout: post
categories: 
tags: 
- cours 
- M1 
- TER 
- NNet
published: true
comments: 
---
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org74db75e">News et TODO-list</a></li>
<li><a href="#orgec1422e">Contenu</a>
<ul>
<li><a href="#org7c08dc1">Séance 1, le 16/01</a></li>
<li><a href="#org9c1dda4">Séance 2, le 30/01</a></li>
</ul>
</li>
</ul>
</div>
</div>
<hr>

<p>
Le <b><b>dossier partagé</b></b> pour ce cours est le <a href="https://drive.google.com/open?id=1z0xtywSzphj4JV6epy4jGcJrBYdGCteZ">suivant</a>. Vous y trouverez
les cours et les ressources nécessaires. 
</p>

<div id="outline-container-org74db75e" class="outline-2">
<h2 id="org74db75e">News et TODO-list</h2>
<div class="outline-text-2" id="text-org74db75e">
<ul class="org-ul">
<li>Pour 13/02 : Finir le tp d'intro à pytorch</li>
<li>Neige le 23/01: cours reporté à la demande générale</li>
<li>Première séance le 16/01, il n'y a pas TER le 09/01 !</li>
</ul>
</div>
</div>



<div id="outline-container-orgec1422e" class="outline-2">
<h2 id="orgec1422e">Contenu</h2>
<div class="outline-text-2" id="text-orgec1422e">
</div>
<div id="outline-container-org7c08dc1" class="outline-3">
<h3 id="org7c08dc1">Séance 1, le 16/01</h3>
<div class="outline-text-3" id="text-org7c08dc1">
<ul class="org-ul">
<li>Cours: Classification binaire / Séparation linéaire</li>
<li>TP : Prise en main python et données imdb</li>
</ul>
</div>
</div>

<div id="outline-container-org9c1dda4" class="outline-3">
<h3 id="org9c1dda4">Séance 2, le 30/01</h3>
<div class="outline-text-3" id="text-org9c1dda4">
<ul class="org-ul">
<li>cours: apprentissage / optimisation</li>
<li>TP : intro pytorch</li>
</ul>

<p>
<b><b>Neige</b></b>: la séance est encore annulée, mais on peut s'avancer en
faisant les TPs d'ici la semaine prochaine.  Il y a 2 notebooks, le
premier est sur numpy et le second sur pytorch. Il est bien de les
faire dans cet ordre.
</p>

<p>
L'objectif important est d'avancer le plus possible dans le TP sur
pytorch après avoir maîtriser le TP sur numpy. Avancer le plus
possible les TP pour la semaine prochaine. 
</p>



<p>
Correction partielle du TP à terminer pour la semaine prochaine: 
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #00ffff;">import</span> torch <span style="color: #00ffff;">as</span> th
<span style="color: #ffffff; background-color: #000000;">loss_fn</span> = th.nn.BCELoss()
<span style="color: #ffffff; background-color: #000000;">learning_rate</span> = 1e-<span style="color: #ffffff; background-color: #000000;">2</span>
<span style="color: #ffffff; background-color: #000000;">optimizer</span> = th.optim.SGD(model.parameters(), <span style="color: #ffffff; background-color: #000000;">lr</span>=learning_rate)

<span style="color: #00ffff;">for</span> epoch <span style="color: #00ffff;">in</span> <span style="color: #b0c4de;">range</span>(<span style="color: #ffffff; background-color: #000000;">1000</span>):
    <span style="color: #ffffff; background-color: #000000;">total</span>=th.zeros([])
    <span style="color: #00ffff;">for</span> i <span style="color: #00ffff;">in</span> <span style="color: #b0c4de;">range</span>(<span style="color: #ffffff; background-color: #000000;">14</span>):
    <span style="color: #ffffff; background-color: #000000;">prediction</span> = model(x[i])    
    <span style="color: #ffffff; background-color: #000000;">loss</span> = loss_fn(prediction, y[i])
    optimizer.zero_grad()  
    loss.backward()        
    optimizer.step()
    <span style="color: #ffffff; background-color: #000000;">total</span>+=loss
    <span style="color: #00ffff;">if</span> epoch%<span style="color: #ffffff; background-color: #000000;">50</span>==<span style="color: #ffffff; background-color: #000000;">0</span>:
    <span style="color: #00ffff;">print</span>(epoch,total)
</pre>
</div>
</div>
</div>
</div>
