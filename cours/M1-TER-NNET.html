---
title: "NNet / Traitement automatique des langues"
date: 2019-02-14
layout: post
categories: 
tags: 
- cours 
- M1 
- TER 
- NNet
published: true
comments: 
---
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org74db75e">News et TODO-list</a></li>
<li><a href="#orgec1422e">Contenu</a>
<ul>
<li><a href="#org7c08dc1">Séance 1, le 16/01</a></li>
<li><a href="#orgb90c833">Séance 2, le 06/02</a></li>
<li><a href="#org1d91ccf">Séance 3, le 13/02</a></li>
<li><a href="#orga43c932">Séance 4, le 20/02</a></li>
<li><a href="#org4b9a1e7">Séance 5, le 27/02</a></li>
</ul>
</li>
<li><a href="#orgbcc48b9">Projets</a>
<ul>
<li><a href="#org41f25c1">Notation automatique de réponses courtes à des questions</a></li>
<li><a href="#org9fb4977">Notation (et explication) pour les bières</a></li>
<li><a href="#orgce7bfdf">Airline Travel Information System (ATIS)</a></li>
<li><a href="#org19a13d8">Classification de tweets</a></li>
<li><a href="#org7e3493e">Conversion graphèmes vers phonèmes</a></li>
<li><a href="#org6c36d5a">Q&amp;A insurance</a></li>
<li><a href="#org71243b9">Quora Question Pairs</a></li>
<li><a href="#orgd3669ec">Toxic Comment Classification</a></li>
<li><a href="#orga9eec24">The Fake-news challenge</a></li>
<li><a href="#org4dae8b4">Amazon review</a></li>
<li><a href="#orgcbdd21a">Hate speech on tweeter</a></li>
</ul>
</li>
</ul>
</div>
</div>
<hr>

<p>
Le <b><b>dossier partagé</b></b> pour ce cours est le <a href="https://drive.google.com/open?id=1z0xtywSzphj4JV6epy4jGcJrBYdGCteZ">suivant</a>. Vous y trouverez
les cours et les ressources nécessaires. 
</p>

<div id="outline-container-org74db75e" class="outline-2">
<h2 id="org74db75e">News et TODO-list</h2>
<div class="outline-text-2" id="text-org74db75e">
<ul class="org-ul">
<li>Pour le 20/02 : Finir le TP 3</li>
<li>Pour 13/02 : Finir le tp d'intro à pytorch</li>
<li>Neige le 30/01: cours annulé, mais 2 notebooks sont disponibles pour
s'avancer un peu (numpy et torch101)</li>
<li>Neige le 23/01: cours reporté à la demande générale</li>
<li>Première séance le 16/01, il n'y a pas TER le 09/01 !</li>
</ul>
</div>
</div>



<div id="outline-container-orgec1422e" class="outline-2">
<h2 id="orgec1422e">Contenu</h2>
<div class="outline-text-2" id="text-orgec1422e">
</div>
<div id="outline-container-org7c08dc1" class="outline-3">
<h3 id="org7c08dc1">Séance 1, le 16/01</h3>
<div class="outline-text-3" id="text-org7c08dc1">
<ul class="org-ul">
<li>Cours: Classification binaire / Séparation linéaire</li>
<li>TP : Prise en main python et données imdb</li>
</ul>
</div>
</div>

<div id="outline-container-orgb90c833" class="outline-3">
<h3 id="orgb90c833">Séance 2, le 06/02</h3>
<div class="outline-text-3" id="text-orgb90c833">
<ul class="org-ul">
<li>cours: apprentissage / optimisation</li>
<li>TP : sur numpy, à faire à la maison</li>
<li>TP : intro pytorch</li>
</ul>

<p>
<b><b>Neige</b></b>: la séance du 30/01 est annulée, mais on peut s'avancer en
faisant les TPs d'ici la semaine prochaine.  Il y a 2 notebooks, le
premier est sur numpy et le second sur pytorch. Il est bien de les
faire dans cet ordre.
</p>

<p>
L'objectif important est d'avancer le plus possible dans le TP sur
pytorch après avoir maîtrisé le TP sur numpy. Avancer le plus
possible les TP pour la semaine prochaine. 
</p>



<p>
Correction partielle du TP sur pytorch qui devrait vous permettre de terminer pour la semaine prochaine: 
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #00ffff;">import</span> torch <span style="color: #00ffff;">as</span> th
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">set the seed (reproductibility)</span>
torch.manual_seed(<span style="color: #ffffff; background-color: #000000;">1</span>) 
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">dimensions of the problem</span>
<span style="color: #ffffff; background-color: #000000;">D_in</span> = <span style="color: #ffffff; background-color: #000000;">2</span>
<span style="color: #ffffff; background-color: #000000;">D_out</span>= <span style="color: #ffffff; background-color: #000000;">1</span>
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Use the nn package to define our model and loss function</span>
<span style="color: #ffffff; background-color: #000000;">model</span> = th.nn.Sequential(
    th.nn.Linear(D_in, D_out),
    th.nn.Sigmoid()    
)
<span style="color: #ffffff; background-color: #000000;">loss_fn</span> = th.nn.BCELoss()
<span style="color: #ffffff; background-color: #000000;">learning_rate</span> = 1e-<span style="color: #ffffff; background-color: #000000;">2</span>
<span style="color: #ffffff; background-color: #000000;">optimizer</span> = th.optim.SGD(model.parameters(), <span style="color: #ffffff; background-color: #000000;">lr</span>=learning_rate)

<span style="color: #00ffff;">for</span> epoch <span style="color: #00ffff;">in</span> <span style="color: #b0c4de;">range</span>(<span style="color: #ffffff; background-color: #000000;">1000</span>):
    <span style="color: #ffffff; background-color: #000000;">total</span>=th.zeros([])
    <span style="color: #00ffff;">for</span> i <span style="color: #00ffff;">in</span> <span style="color: #b0c4de;">range</span>(<span style="color: #ffffff; background-color: #000000;">14</span>):
    <span style="color: #ffffff; background-color: #000000;">prediction</span> = model(x[i])    
    <span style="color: #ffffff; background-color: #000000;">loss</span> = loss_fn(prediction, y[i])
    optimizer.zero_grad()  
    loss.backward()        
    optimizer.step()
    <span style="color: #ffffff; background-color: #000000;">total</span>+=loss
    <span style="color: #00ffff;">if</span> epoch%<span style="color: #ffffff; background-color: #000000;">50</span>==<span style="color: #ffffff; background-color: #000000;">0</span>:
    <span style="color: #00ffff;">print</span>(epoch,total)
</pre>
</div>
</div>
</div>

<div id="outline-container-org1d91ccf" class="outline-3">
<h3 id="org1d91ccf">Séance 3, le 13/02</h3>
<div class="outline-text-3" id="text-org1d91ccf">
<ul class="org-ul">
<li>Cours sur la classification de texte:  représentation sous forme de
sac d'atributs binaires puis de <i>word embeddings</i>.</li>
<li>TP : Classification sur ImDB, de la regression logistique au word
embeddings.</li>
</ul>
</div>
</div>

<div id="outline-container-orga43c932" class="outline-3">
<h3 id="orga43c932">Séance 4, le 20/02</h3>
<div class="outline-text-3" id="text-orga43c932">
<ul class="org-ul">
<li>Cours sur la classification multi-classe, et la génération de
phrase.</li>
<li>Présentation des projets</li>
<li>TP: Classification de texte, suite et fin. Il fait faire et finir
dans l'ordre les TP3 et 4. Complétement !</li>

<li>TP complément: Pour celles ou ceux qui
aurait en effet tout terminer, <a href="http://www.people.fas.harvard.edu/~yoonkim/data/sent-cnn.pdf">l'article suivant</a> propose un modèle
simple pour faire de la classification de texte. Il est considéré
comme un modèle de base. Lire l'article, et proposer une
implémentation, même simplifiée.</li>
</ul>
</div>
</div>


<div id="outline-container-org4b9a1e7" class="outline-3">
<h3 id="org4b9a1e7">Séance 5, le 27/02</h3>
<div class="outline-text-3" id="text-org4b9a1e7">
<ul class="org-ul">
<li><b><b>Travail à rendre</b></b>, avant la séance: bilan sur la classification de
texte.</li>
<li><b><b>Travail à rendre</b></b>, choix du projet</li>
</ul>
</div>
</div>
</div>





<div id="outline-container-orgbcc48b9" class="outline-2">
<h2 id="orgbcc48b9">Projets</h2>
<div class="outline-text-2" id="text-orgbcc48b9">
<p>
<b>Pour le mercredi XXX</b>, vous devez choisir un projet à faire, soit
parmi ceux listés ci-dessous, soit en proposer un, soit on en discute. Puis vous devez
explorer et décrire la tâche en me écrivant un notebook.
</p>

<p>
De manière général, face à un nouveau projet et de nouvelles données, il
faut :
</p>

<ul class="org-ul">
<li>regarder la taille du vocabulaire (en nombre de mots)</li>
<li>est-il possible de le réduire à une taille acceptable ? par exemple
en excluant les mots dont la fréquence est en dessous d'un certain
seuil.</li>
<li>le nombre de caractères</li>
<li>le nombre de phrase (ou de document) à traiter pour l'apprentissage
et pour le test</li>
<li>parfois, c'est à vous de créer la partition (apprentissage,
validation, test)</li>
<li>la distribution de longueurs de phrases.</li>
</ul>

<p>
L'objectif de ce notebook sera d'analyser les données et la tâche afin
de proposer des solutions à expérimenter. Il peut être bien également de
regarder la métrique d'évaluation et voir quels sont les résultats
obtenus par l'état de l'art.
</p>
</div>

<div id="outline-container-org41f25c1" class="outline-3">
<h3 id="org41f25c1">Notation automatique de réponses courtes à des questions</h3>
<div class="outline-text-3" id="text-org41f25c1">
<p>
Les données sont <a href="http://web.eecs.umich.edu/~mihalcea/downloads/ShortAnswerGrading_v2.0.zip">ici pour le téléchargement</a> et leur description est
<a href="http://aclweb.org/anthology/P11-1076">dans cet article</a>. 
</p>

<p>
Lorsque l'on connait:
</p>

<ul class="org-ul">
<li>une question,</li>
<li>une réponse d'un étudiant,</li>
<li>la bonne réponse,</li>
</ul>

<p>
comment prédire la note à donné à la réponse de l'étudiant. Il peut être
aussi intéressant d'essayer d'apprendre à générer la réponse.
</p>
</div>
</div>


<div id="outline-container-org9fb4977" class="outline-3">
<h3 id="org9fb4977">Notation (et explication) pour les bières</h3>
<div class="outline-text-3" id="text-org9fb4977">
<p>
Les données sont disponibles <a href="http://jmcauley.ucsd.edu/cse255/data/beer/beer_50000.json">ici en json</a>. Un exemple d'utilisation de
ces données est décrit dans <a href="https://people.csail.mit.edu/taolei/papers/emnlp16_rationale.pdf">cet article</a>. Mais on peut envisager des
choses plus simple: 
</p>
<ul class="org-ul">
<li>juste un classifieur pour assigner plusieurs notes</li>
<li>expliquer la note pour un classifier plus simple</li>
<li>&#x2026;</li>
</ul>
</div>
</div>

<div id="outline-container-orgce7bfdf" class="outline-3">
<h3 id="orgce7bfdf">Airline Travel Information System (ATIS)</h3>
<div class="outline-text-3" id="text-orgce7bfdf">
<p>
Corpus des années 90, il est dédié à la compréhension de la parole. Le
but est de faire de l'étiquetage de séquence. En entrée, une phrase est
une séquence de mots, et le but est de lui associé une séquence
d'étiquette, une par mot.
</p>

<ul class="org-ul">
<li>Show flights from Boston to New York today</li>
<li>O O O B-dept O B-arr I-arr B-date</li>
</ul>

<p>
Ainsi le mot Show est associé à 'O' pour 'other'; 'Boston' est associé
au lieu de départ, 'B-dept' signifie 'début de départ'; 'York' est
'Inside arrival', &#x2026;
</p>
</div>
</div>

<div id="outline-container-org19a13d8" class="outline-3">
<h3 id="org19a13d8">Classification de tweets</h3>
<div class="outline-text-3" id="text-org19a13d8">
<p>
Partant d'un tweet vu comme une séquence de symboles, effectuer une
classification binaire (positif/négatif). Les données peuvent se
<a href="http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip">télécharger
ici</a>.
</p>

<p>
Un axe peut être de développer un modèle efficace. Les étapes
importantes:
</p>

<ul class="org-ul">
<li>Exploration puis préparation des données sous forme exploitable</li>
<li>Filtrage des données éventuel</li>
<li>Préparation d'une partition : apprentissage, validation, test</li>
<li>essayer différents modèles</li>
</ul>

<p>
Un autre axe est de partir de cet article
<a href="https://www-cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf">en
pdf</a> qui parle, entre autre, de comment collecter des données tweeter
pour faire de la classification.
</p>
</div>
</div>

<div id="outline-container-org7e3493e" class="outline-3">
<h3 id="org7e3493e">Conversion graphèmes vers phonèmes</h3>
<div class="outline-text-3" id="text-org7e3493e">
<p>
Partant d'un mot vue comme une séquence de lettres (les graphèmes), le
but est de générer une séquence de phonèmes. Les données nettalk sont
décrites
<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.names">ici</a>
et disponible
<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.data">ici</a>.
</p>

<p>
Il y a deux types d'annotation que l'on peut vouloir générer :
</p>

<ul class="org-ul">
<li>au moins la séquence de phonèmes (c'est le but premier),</li>
<li>mais également la séquence d'accentuation.</li>
</ul>

<p>
La séquence d'accentuation peut éventuellement aider à prédire les
phonèmes. Il existe alors plusieurs pistes à explorer.
</p>

<p>
Remarque : penser à vérifier si la séquence à générer est toujours de la
même longueur que la séquence de graphèmes
</p>
</div>
</div>

<div id="outline-container-org6c36d5a" class="outline-3">
<h3 id="org6c36d5a">Q&amp;A insurance</h3>
<div class="outline-text-3" id="text-org6c36d5a">
<p>
L'objectif est pouvoir sélectionner une réponse à une question. Les
données viennent du domaine de l'assurance. Les données brutes viennent
<a href="https://github.com/shuzi/insuranceQA.git">de ce site</a>.
</p>

<p>
Une version plus simple peut se télécharger
<a href="https://github.com/codekansas/insurance_qa_python">ici</a>
</p>

<p>
Cette
<a href="http://benjaminbolte.com/blog/2016/keras-language-modeling.html">page</a>
explique beaucoup de choses (certaines sont peut être soit trop
complexes, soit inutiles). Elle cite entre autres des articles décrivant
des modèles performants et qui peuvent donner des idées.
</p>
</div>
</div>


<div id="outline-container-org71243b9" class="outline-3">
<h3 id="org71243b9">Quora Question Pairs</h3>
<div class="outline-text-3" id="text-org71243b9">
<p>
Le challenge <a href="https://www.kaggle.com/c/quora-question-pairs">https://www.kaggle.com/c/quora-question-pairs</a>
</p>
</div>
</div>

<div id="outline-container-orgd3669ec" class="outline-3">
<h3 id="orgd3669ec">Toxic Comment Classification</h3>
<div class="outline-text-3" id="text-orgd3669ec">
<p>
<a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge</a>,
</p>
</div>
</div>


<div id="outline-container-orga9eec24" class="outline-3">
<h3 id="orga9eec24">The Fake-news challenge</h3>
<div class="outline-text-3" id="text-orga9eec24">
<p>
<a href="http://www.fakenewschallenge.org/">http://www.fakenewschallenge.org/</a>
</p>
</div>
</div>

<div id="outline-container-org4dae8b4" class="outline-3">
<h3 id="org4dae8b4">Amazon review</h3>
<div class="outline-text-3" id="text-org4dae8b4">
<p>
<a href="https://snap.stanford.edu/data/web-Amazon.html">https://snap.stanford.edu/data/web-Amazon.html</a>
</p>
</div>
</div>

<div id="outline-container-orgcbdd21a" class="outline-3">
<h3 id="orgcbdd21a">Hate speech on tweeter</h3>
<div class="outline-text-3" id="text-orgcbdd21a">
<p>
<a href="https://www.kaggle.com/vkrahul/twitter-hate-speech">https://www.kaggle.com/vkrahul/twitter-hate-speech</a>
</p>
</div>
</div>
</div>
