---
title: "Introduction to Deep Learning, ESPCI"
date: 2021-01-04
layout: page
categories: 
tags: 
- cours 
- NNet 
- espci
published: true
comments: 
---
<hr>


<p>
This course is an introduction to deep-learning approach with lab
sessions in <a href="https://pytorch.org/">pytorch (python module)</a>.  The goal is to understand the
data-driven approach and to be able to efficiently experiment with deep-learning on real data. 
</p>


<div id="outline-container-org865109a" class="outline-2">
<h2 id="org865109a">News</h2>
<div class="outline-text-2" id="text-org865109a">
<ul class="org-ul">
<li>Registration for the project: make up your team and add a line in this</li>
</ul>
<p>
<a href="https://docs.google.com/spreadsheets/d/1kIfY6G_TtT3F2SSnunLJcjgS2YegKNb1Fr-B_johhag/edit?usp=sharing">form</a>. Deadline for registration: 8/03/2021 ! 
</p>

<ul class="org-ul">
<li>The next lab session will be the 1st of March. The topic is
Convolution for text classification. The notebook is <i>lab-imdb-text-convolution</i>.</li>

<li>The next lab session will be the 1st of February. The topic is
pytorch and deep-learning. The notebook is <i>lab-fashion-mnist</i>.</li>

<li><b><b>Homework assignement 2</b></b>: see the drive, for the notebooks.  
<ul class="org-ul">
<li>First follow the notebook called <i>idl-pytorch-starter.ipynb</i></li>
<li>Then the assignment is also a notebook : <i>hw-2-idl-espci.ipynb</i></li>
</ul></li>
<li><b><b>The deadline is the 1st of February morning</b></b>, before the lab
session of course.</li>

<li>The first lab session is next monday (January the 18th): 
<b><b>TODO:</b></b> go through  the notebook in the drive (in the lab repository): <i>lab-1-numpy-basics.ipynb</i>. Be sure (see below) how to use it.</li>

<li>The first homework is available on the drive <a href="https://drive.google.com/file/d/1RKGGoqFoFtPt6A_uU9B05cfXl39iM_Ir/view?usp=sharing">following this link</a>. 
<b><b>The deadline is the 11th of january morning</b></b>, before the course.</li>

<li>First course: January the 4th. Early in the morning and remote.</li>
</ul>
</div>
</div>


<div id="outline-container-org0883a09" class="outline-2">
<h2 id="org0883a09">The resources / drive</h2>
<div class="outline-text-2" id="text-org0883a09">
<p>
<a href="https://drive.google.com/drive/folders/14qRch6tlVatxf7ZidOv_MwwStaQmXagK?usp=sharing">Look at this drive</a> for the slides and the material of lab sessions.
</p>
</div>
</div>


<div id="outline-container-org7e2b235" class="outline-2">
<h2 id="org7e2b235">python and Notebooks: how to</h2>
<div class="outline-text-2" id="text-org7e2b235">
<p>
We will use python 3 (plus pytorch library) and notebooks. If you need to work with own computer, there are 2 ways: 
</p>
<ul class="org-ul">
<li>install anaconda 3 on your computer: <a href="https://www.anaconda.com/products/individual">see this page</a>.</li>
<li>use <a href="https://colab.research.google.com/">colab</a> with a google account (the easiest, nothing todo)</li>
</ul>

<p>
To use files stored on your google drive you can add in your colab notebook: 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #00ffff;">from</span> google.colab <span style="color: #00ffff;">import</span> drive

drive.mount(<span style="color: #ffa07a;">'/content/gdrive'</span>)
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">in my drive, I have a directory "Colab Notebooks"</span>
<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">the dataset is uploaded there</span>
<span style="color: #eedd82;">root_path</span> = <span style="color: #ffa07a;">'gdrive/My Drive/Colab Notebooks/'</span>
</pre>
</div>
<p>
You can also upload files from your device: 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #00ffff;">from</span> google.colab <span style="color: #00ffff;">import</span> files
<span style="color: #eedd82;">upl</span> = files.upload()
</pre>
</div>


<p>
If you are not familiar with python notebooks, see <a href="https://realpython.com/jupyter-notebook-introduction/">this page</a>. 
</p>
</div>
</div>




<div id="outline-container-orga58ef05" class="outline-2">
<h2 id="orga58ef05">Expected schedules</h2>
<div class="outline-text-2" id="text-orga58ef05">
<p>
It starts in january 2021 (the 4th). The course is scheduled on
monday, starting at 8:30 in the morning.
</p>

<p>
The first part: 
</p>
<ul class="org-ul">
<li>4/01, course: introduction and basics on machine learning
<ul class="org-ul">
<li>The main tasks</li>
<li>Objective function</li>
<li>Optimisation with gradient descent</li>
</ul></li>

<li>11/01, course on feed-forward neural networks
<ul class="org-ul">
<li>Multi-class classification</li>
<li>From linear to non-linear classification</li>
<li>The feed-forward architecture and the back-propagation algorithm</li>
</ul></li>

<li>18/01, <b><b>lab session</b></b> : machine learning and python, first steps 
<ul class="org-ul">
<li>numpy and matplotlib</li>
<li>logistic regression by hand</li>
<li>Non-linear cases</li>
</ul></li>

<li>25/01, course on  deep-learning
<ul class="org-ul">
<li>Deep networks</li>
<li>Drop out, regularization  and other tricks</li>
<li>pytorch overview</li>
</ul></li>

<li>01/02, <b><b>lab session</b></b> : deep-learning in pytorch</li>
</ul>

<p>
The second part: 
</p>
<ul class="org-ul">
<li>08/02, course: Sequence processing with convolutional deep-networks
<ul class="org-ul">
<li>sequence processing, classification and generation</li>
<li>Case study: sentence classification with 1D convolution</li>
</ul></li>
<li>15/02, course: Recurrent net, and convolution for images
<ul class="org-ul">
<li>Convolution 1D and 2D</li>
<li>Sequence generation</li>
<li>Recurrent architecture</li>
</ul></li>
<li>01/03, <b><b>lab sesion</b></b>: convolutional net</li>
<li>22/03, course: Advanced architecture 
<ul class="org-ul">
<li>From reccurent to LSTM architecture</li>
<li>Sequence to Sequence model</li>
<li>Transformer overview</li>
</ul></li>
<li>29/03, course: Advanced architecture - part 2 / Project</li>
</ul>
</div>
</div>


<div id="outline-container-orgcf3b3c0" class="outline-2">
<h2 id="orgcf3b3c0">Projects</h2>
<div class="outline-text-2" id="text-orgcf3b3c0">
<p>
Here, you can find a list of possible projects. Feel free to interact with me. For some of them, just ask me the data, otherwise a link is provided. Of course, you can also propose a project. 
This section is under construction and maybe some projects will be added as soon as I will have more feedbacks from my colleagues. 
</p>


<ul class="org-ul">
<li>Reconstruction of the vorticity field of a flow behind a cylinder from a handful sensors on the cylinder surface</li>
</ul>

<a href="https://arxiv.org/abs/1906.07672">
<img src="/assets/figs/cylinder.png" alt="Velocity fields" style="width:300px; margin:0px auto;display:block"/>
</a>


<ul class="org-ul">
<li>The mean sea surface temperature reconstruction <a href="https://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.html">from weekly sea surface temperatures for the last 26 years</a>. You can also have access to other measures.</li>
</ul>

<a href="https://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.html">
<img src="/assets/figs/sea.png" alt="Sea surface temperature" style="width:300px; margin:0px auto;display:block"/>
</a>


<ul class="org-ul">
<li>Deep sequence models for protein classification: there is a <a href="https://academic.oup.com/bioinformatics/article/36/8/2401/5698270">recent paper on this topic</a> and data can be available. We can try different models (maybe simpler) for the same task.</li>

<li>Chemistry: Predict the standard density of pure fluids, using a newly compiled database. From SMILES description, how can we predict density ? Ask me for the data and tools.</li>

<li>Classify sleep and arousal stages from physiological signals including: electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), electrocardiology (EKG), and oxygen saturation (SaO2). <a href="https://physionet.org/content/challenge-2018/1.0.0/">See the challenge page for more details</a></li>

<li>Classify, from a single short ECG lead recording (between 30 s and 60 s in length), whether the recording shows normal sinus rhythm, atrial fibrillation (AF), an alternative rhythm, or is too noisy to be classified: <a href="https://physionet.org/content/challenge-2017/1.0.0/">The challenge page</a>. Other datasets can be nice: 
<ul class="org-ul">
<li><a href="https://mimic.physionet.org/">https://mimic.physionet.org/</a></li>
<li><a href="https://www.physionet.org/data/">https://www.physionet.org/data/</a></li>
<li><a href="https://outbox.eait.uq.edu.au/uqdliu3/uqvitalsignsdataset/index.html">https://outbox.eait.uq.edu.au/uqdliu3/uqvitalsignsdataset/index.html</a></li>
</ul></li>
</ul>



<ul class="org-ul">
<li><a href="https://www.kaggle.com/c/LANL-Earthquake-Prediction/data">Using seismic signals to predict the timing of laboratory earthquakes</a>.</li>

<li>Quantum-mechanical molecular energies prediction from the raw molecular geometry: <a href="http://moleculenet.ai/datasets-1">see the QM7 database</a>.</li>

<li>Classify Molecule polarization: the data comes from time-lapse
fluorescence microscopy images of the bacterium Pseudomonas fluorescens SBW25. Each image is an individual bacterial cell. These bacteria produce a molecule called pyoverdin which is naturally fluorescent, so the images show the distribution of this molecule inside the cells. We have discovered that there are two distribution patterns of this molecule: homogeneous, or accumulated at the cell pole ("polarized").</li>
</ul>


<ul class="org-ul">
<li>Jet Flavor Classification in High-Energy Physics: <a href="http://mlphysics.ics.uci.edu/">http://mlphysics.ics.uci.edu/</a></li>

<li>Recognize decays in real high energy physics experiment: <a href="https://www.kaggle.com/c/beta-beta-decay-identification/data">https://www.kaggle.com/c/beta-beta-decay-identification/data</a></li>

<li>A project associated with the course of statistical physics</li>
</ul>
</div>
</div>
